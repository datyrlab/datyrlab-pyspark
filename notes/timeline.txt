https://twitter.com/datyrlab

download the framework
https://github.com/datyrlab/python-pyspark-framework

-----------------------------------------

PySpark Framework - Python Functional and Object Orientated Programming - Part 1 - ETL
https://youtu.be/EttGKeT4e3U

0:00 - intro - welcome if you're a beginner
2:12 - intro - Python functional and OOP programming with Spark
4:41 - intro - we'll build a Spark framework starting with ETL
5:53 - intro - overview of the project structure
11:53 - intro - overview of the example data
16:08 - create a project structure for directories and files
24:49 - create a class object for pyspark and import modules
34:30 - install missing module pyspark
38:24 - class basics and defining arguments
48:57 - job - create var for root path to our project directory
54:30 - job - create logs using python's logger module
1:05:55 - job - add root dir path to sys.path then test import of our class
1:23:56 - class - pass a class var or dictionary as self to a method attr
1:33:37 - job - function to read a config json file & convert to dict
1:54:45 - job - function to call class method for a spark session
2:02:56 - class - create method for spark session
2:13:54 - downgrade pyspark version - must be same version as spark
2:18:15 - class - add function to print a dict of our spark settings
2:36:17 - job - function to stop spark session
2:40:27 - class - function to set spark logging
2:46:21 - log4j.properties - update to silence spark logging
3:00:19 - summary of our framework and code so far
3:07:26 - job/ class - rename config/ conf argument
3:11:14 - job - function to call class method to import data
3:28:26 - class - create method to import data
3:33:44 - class - import data - function if directory or file
3:42:59 - class - import data - function if path is a directory
3:46:26 - class - import data - method to list a directory and filter files
4:21:20 - class - create method to convert file data to dataframe
4:24:21 - class - dataframe - import data - add functions for file type
5:02:18 - class - dataframe - convert CSV file to spark dataframe
5:09:00 - job - function to transform dataframe
5:21:15 - class - dataframe - convert mulitple JSON files to one dataframe
5:28:53 - job - pass all imported dataframes to job transform function
5:38:45 - job - transform - flatten nested JSON dataframe
5:49:38 - job - transform - cast columns types, Date and Integer

-----------------------------------------

PySpark Framework - Python Functional and OOP - Part 2 - ETL code clean up & debug
https://youtu.be/i00HQn9pnkI

0:00 - code clean up - class - create a method to open JSON
9:28 - code clean up - jobs - undo nested functions
13:11 - code clean up - class - remove functions as arguments
15:51 - code clean up - class - move if statements into functions
21:27 - code clean up - remove printing anything to terminal
22:58 - class - create a method to write dataframe schema to file
58:42 - github code repository
1:00:43 - code clean up - class - move if statement into function
1:14:00 - code clean up - jobs - move function call showMySchema
1:18:00 - jobs - function to convert dataframes to temp SQL tables
1:31:14 - jobs - pass dataframes to function as list of tuples
1:35:53 - class - new method to create spark temporary SQL tables
1:39:11 - jobs - list comprehension + lambda to iterate list
1:48:03 - class - parse tuple dataframe and create temp SQL table
1:53:55 - class - update debugging to write JSON files for tables












